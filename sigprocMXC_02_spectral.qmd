# Crash course on the fourier transform

The Fourier transform is a pretty wide topic. It is used in many  fields, such as mathematics, statistics, physics or engineering.

![FourierTransform](sigprocMXC_02_spectral/fourierTransformClear.png){#fig-transform-clear}

The idea of the Fourier transform is to transform the data from time domain to
frequency domain, and vice versa (inverse transform). @fig-transform-clear
panel A1 shows a signal in atime domain with a duration of two seconds.
Panel A2 shows the same signal in the frequency domain, with a single peak at
the three Hertz mark, as there are three cycles per second. The peak height is
one unit energy (amplitude), and 0 in any other point, as there are no other
frequencies. The signal in panel B1 has a peak at 8 Hertz (panel B2), with a
smaller amplitude (0.5 in both panels). Panel C1 shows the sum of these two
signals. However, in the time domain plot is not as easy to interpret as in the
other two examples, whereas the frequency domain clearly shows two distinct
spectral components with different frequencies and amplitudes. Frequency domain
visualization becomes even more useful if you start adding noise, whereas the
plot would be unreadable in the time domain
(@fig-transform-noisy contains 4 components with *broadband noise*).

![FourierTransform](sigprocMXC_02_spectral/fourierTransformNoisy.png){#fig-transform-noisy}

If a signal has certain features (sine-like repeating patterns)

The point is that there is the same information in both domains, but it is
easier to interpret in the frequency domain. Sine-like signals are particularly
amenable to this type of analysis, whereas other may be more difficult to
understand.

## How does the Fourier transform work?

How do you get from the time domain into the frequency domain using the
Fourier transform? On layman terms, you start off with a signal in the time
domain, and then you take a sine wave that you want to match against the signal.
The similarity between the signal and the wave is estimated with the
*dot product*. The result is a number indicating how much presence the wave
has within the signal. If we repeat this for waves with different frequencies,
we can make a frequency domain plot, where each of the bars is the similarity
of a wave obtained from the dot product (Fourier coefficients). The full plot
is called an amplitude or power spectrum, depending on wether the Fourier
coefficients have been squared or not. This procedure is called the forward
Fourier transform (from time domain to frequency domain).

Inverse Fourier transform, works in a similar way, allowing to transform data
in the frequency domain back to the time domain. It works by taking the Fourier coefficients, mapping them back onto pure sine waves and then summing them all
together. The usefulness of this technique has to do with some shortcuts that
people use in signal processing that are provided by the convolution theorem.

## Uses

There are two major uses of the Fourier Transform. One is making signals easier
to understand (spectral analysis), getting insights that would more difficult
to extract from the time domain. The other reason is because signal processing
operations in the frequency domain tend to be conceptually easier and faster
to implement on computers than the equivalent computations on the time domain.
For example filtering (convolution).

# Frequency resolution

Frequency resolution is the distance between any two successive frequency bins.
It is controlled by the sampling rates and of the number of time points in the
signal. The sampling rate leads to an important number in signal processing
and spectral analysis, which is called the Nyquist frequency.

The Nyquist frequency is very simply just half of the sampling rate. So if
you measure your data with a sampling rate of 1024Hz, then the Nyquist
frequency is 512Hz.

Now when you apply the forward Fourier transform on a signal the frequencies
you extract range from 0 (DC point), up to the Nyquist frequency, which is one
half of the sampling rate. The number of points you get between these two 
is a direct result of the number of time points in the signal.

* If you only have a few time points in the signal, then you're going to get a relatively
sparse frequency resolution.

* If you have more time points in the signal for the same sampling rate (a longer signal), then you're going to more data points between Zero and Nyquist (better frequency resolution).

If you want to increase the frequency resolution to get more frequencies out
of the signal, then you either need to have have more time points in the signal,
or you can do something called zero padding, which means adding more zeros to
the end of the signal, and that effectively makes the signal longer without
adding any new information into the signal.

# Fourier transform for spectral analyses

## Synthetic data

```{python}
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from scipy.io import loadmat, wavfile
from scipy import fftpack
from scipy import signal as spysig
import copy
```

In this video, we will go through some examples of the Fourier transform.
Some examples are based on simulated data, which can be very useful, as the
user can change the input signals (e.g., noise amount) with a known ground
truth.

We are going to simulate a signal with a sampling rate of 1234Hz with a length
of two seconds. In other words, 1234 time points per second per the definition
of the sampling rate in Hertz.

The time vector goes from 0 to the number of points minus one divided by the
sampling rate. Just linear indexing normalized by the sampling rate. Note this
vector does not go up to exactly, exactly two seconds. This is caused
by starting off at 0, if we started at one it would reach exactly two seconds.

```{python}
## Generate a multispectral noisy signal

# simulation parameters
srate = 1234 # in Hz
npnts = srate*2 # 2 seconds
time  = np.arange(0,npnts)/srate

# frequencies to include
frex  = [ 12,18,30 ]
```

If you go from zero up to the number of points, this is going to be two seconds
plus one sampling rate. Now, that's not really wrong per se, but it's
technically incorrect if you want to get two seconds of data.

So I'm going to generate a multi-spectral signal with three frequencies: 12Hz,
18Hz and 30Hz. First we initialize the signal to be just zeros plus noise.
Then we loop over the frequencies adding sine waves to the noise 
($\sin \left( 2 \pi f t \right)$). The indices are used as amplitudesS.

```{python}
signal = np.zeros(len(time))

# loop over frequencies to create signal
for fi in range(0,len(frex)):
    signal = signal + (fi+1)*np.sin(2*np.pi*frex[fi]*time)

# add some noise
signal = signal + np.random.randn(len(signal))
```

Once the signal has been generated, we extract the coefficients using the fast
Fourier transform (FFT). Then we use the absolute value (`abs`) to get the
magnitude from the coefficients, which is the amplitude.

If we intend to retrieve the original units of the signal, you do need to
normalize this data by multiplying by 2 and then divide by the number of time
points in the signal. However, if you are just interested in the shape of the
spectrum, you don't need either of these two.

The frequency vector is $1 + (n/2)$ (half of the time points) frequency bins
ranging between $0$ and Nyquist (half of the sampling rate).

```{python}
# amplitude spectrum via Fourier transform
signalX = fftpack.fft(signal)
signalAmp = 2*np.abs(signalX)/npnts

# vector of frequencies in Hz
hz = np.linspace(0,srate/2,int(np.floor(npnts/2)+1))

# Undo the transformation
remade = np.real(fftpack.ifft(signalX))
```

```{python}
## plots

plt.plot(time,signal, lw=1, label='Original')
plt.scatter(time, remade, s=4,c='k', lw=1, zorder=999,label='IFFT reconstructed')

plt.xlim(0.9, 1.1)
plt.xlabel('Time (s)')
plt.ylabel('Amplitude')
plt.title('Time domain')
plt.legend()
plt.show()

plt.stem(hz,signalAmp[0:len(hz)],'k')
plt.xlim([0,np.max(frex)*3])
plt.xlabel('Frequency (Hz)')
plt.ylabel('Amplitude')
plt.title('Frequency domain')
plt.show()
```

Then we plot the time domain signal and the amplitude spectrum of the signal.
You can clearly see that there are some rhythmicity components to this signal
and also a little bit of noise added here. The amplitude spectrum shows the
three peaks with the specified frequencies ($x$) and amplitudes ($y$) which
stand out from a background of uniformly distributed random noise (in the 
freq. domain; broadband noise?).

If we take the inverse Fourier transform (IFT) and we plot it in the time
domain we can see the original and the reconstructed signal overlap perfectly:
we can go into the frequency domain through the Fourier transform and then
apply the inverse Fourier transform and you get back the original signal
flawlessly.

Note if the signal is noisy enough, the components will not be clear on the
frequency domain.

If we increase the amplitude of the noise by multiplying by $3$ the signal 
remains understandable on the frequency domain. If we multiply by $6$, $16$,
$20$... the peaks stand less and less, with some becoming larger than the peaks
we introduced in the synthetic signal.

## Real world data: Search volume

```{python}
## example with real data based on 
# https://trends.google.com/trends/explore?date=today%205-y&geo=US&q=signal%20processing

data = {'original': np.load('sigprocMXC_02_spectral/GoogleTrends_SignalProcessing.npy')}
N = len(data['original'])
hz = np.linspace(0,52,N)

# possible normalizations...
data['centered'] = data['original'] - np.mean(data['original'])
data['detrended'] = spysig.detrend(data['original'])

# Plotting
fig, axes = plt.subplots(3, 2, sharex='col')
axes[0, 0].set_title('Time domain')
axes[0, 1].set_title('Frequency domain (power)')
for row_id, (ylabel, ydata) in enumerate(data.items()):

    axes[row_id, 0].set_ylabel(ylabel.capitalize())
    axes[row_id, 0].plot(ydata,'k')
    axes[row_id, 1].plot(hz, np.abs( fftpack.fft( ydata )/N )**2,'m')
    axes[row_id, 1].set_xlim(left=0, right=12)

axes[-1, 0].set_xlabel('Time (weeks)')
axes[-1, 1].set_xlabel('Frequency (norm)')
fig.tight_layout()
```

`GoogleTrends_SignalProcessing.npy` contains the search volume for
'signal processing' as depicted by [trends.google.com](https://trends.google.com).
These numbers are already normalized and have a weekly time step.

We get the amplitude spectrum by calcualating the FFT,
(dividing by the sample count?), and calculating the absolute value.
If it squared, it becomes the power spectrum.

On the left column of FIGURE you can see the weekly search volume seems to show
some rythmicity, and a slight downwards trend. The frequency domain plot for the
original signal seems to show nothing. That's not the case! It is heavily skewed
by the zero frequency: the DC offset (dark current offset?), which captures the
average over the full duration of the signal.

What is happening is the original signal has an average around 60, which becomes
3600 once it has been squared. Again, this first point only reflects the average
search volume, as it is not 0.

So it's often useful in signal processing to eliminate the DC component.
It can be removed during the plotting, or the data itself can be normalized,
for example, by removing the signal average, or by applying detrending.
Once any of these methods has been applied, the frequency domain plot becomes
a lot more readable now that the DC offset is 0.

Detrending may not be adequate on this case because it removes the downward
trend, which is a valid part of the signal. Removing the mean may be the right
procedure, retaining the slow decrease.

Interpretation. The data depicts the normalized search volume per week.
The ftequency vector (`hz`) goes from 0 to 52 with `N` steps (the length of the
data vector). This is different from the example with synthetic data where we
said $n/2 + 1$. Here we're applying a plotting trick to go all the way up to
$N$ because now I don't need to cut off the Fourier coefficients half way
through. This means that we can interpret these numbers as a fraction of a year.

The large peak at $2$ means that every $26$ weeks ($52/2$, twice a year), 
there is a peak in the search volume for signal processing. My guess is that
this corresponds to the semester schedule where twice a year people are starting
to learn about signal processing in their engineering course or perhaps a
statistics or data analysis course, and they start searching the internet for
signal processing information.

There's also a peak at one hertz, indicating the presence of an annual cycle.
There is also a large peak at low frequencies which could be interpreted as a
low frequency fluctuation in the signal. However, this is caused by the slow
linear trend, which requires a lot of energy at a kind of 1/f shape in the
frequency spectrum, and has spread over the two first coefficients, but it only
has been fully removed from the first (DC component removal).

---
# VIDEO: Welch's method
---



```python
# load data and extract
matdat  = loadmat('EEGrestingState.mat')
eegdata = matdat['eegdata'][0]
srate   = matdat['srate'][0]

# time vector
N = len(eegdata)
timevec = np.arange(0,N)/srate

# plot the data
plt.plot(timevec,eegdata,'k')
plt.xlabel('Time (seconds)')
plt.ylabel('Voltage (\muV)')
plt.show()
```


```python
## one big FFT (not Welch's method)

# "static" FFT over entire period, for comparison with Welch
eegpow = np.abs( scipy.fftpack.fft(eegdata)/N )**2
hz = np.linspace(0,srate/2,int(np.floor(N/2)+1))

```


```python
## "manual" Welch's method

# window length in seconds*srate
winlength = int( 1*srate )

# number of points of overlap
nOverlap = np.round(srate/2)

# window onset times
winonsets = np.arange(0,int(N-winlength),int(winlength-nOverlap))

# note: different-length signal needs a different-length Hz vector
hzW = np.linspace(0,srate/2,int(floor(winlength/2)+1))

# Hann window
hannw = .5 - np.cos(2*np.pi*np.linspace(0,1,int(winlength)))/2

# initialize the power matrix (windows x frequencies)
eegpowW = np.zeros(len(hzW))

# loop over frequencies
for wi in range(0,len(winonsets)):
    
    # get a chunk of data from this time window
    datachunk = eegdata[ winonsets[wi]:winonsets[wi]+winlength ]
    
    # apply Hann taper to data
    datachunk = datachunk * hannw
    
    # compute its power
    tmppow = np.abs(scipy.fftpack.fft(datachunk)/winlength)**2
    
    # enter into matrix
    eegpowW = eegpowW  + tmppow[0:len(hzW)]

# divide by N
eegpowW = eegpowW / len(winonsets)


# plotting
plt.plot(hz,eegpow[0:len(hz)],'k',label='Static FFT')
plt.plot(hzW,eegpowW/10,'r',label='Welch''s method')
plt.xlim([0,40])
plt.xlabel('Frequency (Hz)')
plt.legend()
plt.show()
```


```python
## Python's welch

# create Hann window
winsize = int( 2*srate ) # 2-second window
hannw = .5 - np.cos(2*pi*linspace(0,1,winsize))/2

# number of FFT points (frequency resolution)
nfft = srate*100

f, welchpow = scipy.signal.welch(eegdata,fs=srate,window=hannw,nperseg=winsize,noverlap=winsize/4,nfft=nfft)

plt.semilogy(f,welchpow)
plt.xlim([0,40])
plt.xlabel('frequency [Hz]')
plt.ylabel('Power')
plt.show()
```


---
# VIDEO: Spectrogram of birdsong
---



```python
## load in birdcall (source: https://www.xeno-canto.org/403881)

fs,bc = scipy.io.wavfile.read('XC403881.wav')


# create a time vector based on the data sampling rate
n = len(bc)
timevec = np.arange(0,n)/fs

# plot the data from the two channels
plt.plot(timevec,bc)
plt.xlabel('Time (sec.)')
plt.title('Time domain')
plt.show()

# compute the power spectrum
hz = np.linspace(0,fs/2,int(floor(n/2)+1))
bcpow = np.abs(scipy.fftpack.fft( scipy.signal.detrend(bc[:,0]) )/n)**2

# now plot it
plt.plot(hz,bcpow[0:len(hz)])
plt.xlabel('Frequency (Hz)')
plt.title('Frequency domain')
plt.xlim([0,8000])
plt.show()
```


```python
## time-frequency analysis via spectrogram

frex,time,pwr = scipy.signal.spectrogram(bc[:,0],fs)

plt.pcolormesh(time,frex,pwr,vmin=0,vmax=9)
plt.xlabel('Time (s)'), plt.ylabel('Frequency (Hz)')
plt.show()
```

In this video, I'm going to introduce you to a procedure called Welch's Method.

This is a slight variation of the fast Fourier transform that you learned about in the previous video.

And the goal of Welch's method is to do spectral analysis with the FFT, but to increase the signal

to noise a little bit, particularly if there are non stationarities in the signal, meaning that the

characteristics of the signal are changing a little bit over time.

So the way to apply the Fourier transform for spectral analysis that you learned about in the previous

video is something like this.

So you take the entire time series and you compute one Fourier transform over the entire window of time

and that's going to give you some amplitude spectrum or a power spectrum if you square these values.

I often refer to this approach as the static FFT because you are treating this entire signal as if it's

static, as if it doesn't really change over time.

Now, the idea of Welch's method is to cut up the Time series into a set of blocks or epochs or windows,

and then you would apply the Fourier transform separately on this window, separately on this window,

separately on this window and so on.

That's going to give you a number of power spectra.

So however many windows you have, you have that many spectra, and then you average the amplitude spectra

or the power spectra together after you've computed them separately for each window.

Now, if the features of the signal are the same over the entire window of time, then these two methods

are going to be basically the same.

Welch's method and the static FFT method.

But if there is noise that's changing over time or if the some of the characteristics of the signal

are changing over time, then Welch's method is often going to give you a slightly cleaner result,

slightly higher signal to noise.

In this visualization, you see that these different windows are non-overlapping.

So the second window begins where the first window ends and so on.

That is one way of doing it.

But it's also possible and actually more commonly done to have these windows be overlapping.

So you might have, for example, 50% overlap between the successive windows.

And that would mean, for example, that this second window would begin over here.

So the first window would look like this, the second window would look like this, and then this one

would be the third window and so on.

Now I'll switch to Matlab so you can see how Welch's method gets implemented.

To illustrate this concept, I'm going to use some real data.

This is EEG data.

So data of electrical brain activity, recordings in a human and the rest of this file name says resting

state.

And that means that while the EEG data were recorded, while the electrical brain activity was recorded,

this individual was just sitting quietly with their eyes closed and relaxing.

So let's load in this data file and whenever you load in a new data file into the Matlab workspace,

it's useful to type who's to see what is contained inside this math file.

So there's two variables EEG data, and you can see that that's just some really long vector.

This is voltage fluctuations over time at one electrode, one measurement sensor.

And then we have this variable s rate, which is the sampling rate.

And these data were recorded at a sampling rate of 1024Hz.

There is no time vector that's present in this mat file in this data set.

So I'm going to need to create my own time vector and I'm going to do that the same way.

I always create these time vectors, which is to go from zero to n minus one, where N is the number

of time points in the signal, and then that's divided by the sampling rate.

So here we make a plot of the EEG data.

This is what it looks like.

You can see there's 100 and 20s or it's two minutes of recordings.

Now, you don't really see a whole lot.

This actually looks more or less indistinguishable from noise.

But you can zoom in and have a look and you'll see that there are some regular fluctuations at different

time scales.

So we want to do is make this a little more quantitative.

We want to understand if there really are these fluctuations over time and if they have some particular

characteristic frequency.

So to start with, I'm going to compute the power over the entire EEG time series.

So this is the static Fourier transform.

All right.

So I'll run this and this is going to be plotted a little bit further down.

First, I want to show you Welch's method.

So this is what I call in quotes manual Welch's method, because I'm writing out all the code.

You'll see that that contrasts with the P Welch function that computes Welch's method automatically.

And then I'll show you in the next cell.

So here I define how long the windows are going to be in terms of multiples of the sampling rate.

So this corresponds to seconds.

So the window length will be one second, which is 1024 time points.

And here I specify the number of points to overlap and that I just picked more or less randomly to be

one half of the sampling rate, which corresponds to one half of a second.

So these will overlap by 50% of the total window length.

Here I define the onset time.

So that's basically just defining where I start each Fourier transform.

So we can zoom in here a bit.

So let's see, I'll zoom in even more.

So one Fourier transform window is going to go from 12 to 13 seconds.

So like this.

And then the next.

So then right, so the starting point for this window would be 12 and then the next one, the next window

is going to be starting at 12.5 and going to 13.5.

So then the starting points have to go every 500 milliseconds, every half of a second.

Okay.

And then that's what is defined here on this line.

Now, you'll remember in the first lecture that I gave in this section of the course.

So that was the crash course on the Fourier transform.

Or maybe you know this from my other course on the Fourier transform or a course that you've taken on

the Fourier transform that the frequency resolution of the Fourier transform is given by the number

of time points.

So here in this static Fourier transform we have a lot of time points, so n time points.

But here for this window, there's fewer time points.

The number of time points in each Fourier transform will correspond to the window length.

So basically all of that means is that we need a different frequencies vector for the static power spectrum

versus the smaller Fourier transform that's going to result from Welch's method.

I will get back to this line in a minute.

Here I am, initializing the power to be zero and it's going to be zeros, basically, just because

I'm going to keep adding power onto itself to compute the average over all of these window onsets.

So here's a loop where I go over the window onsets.

Here, I get a chunk of the EEG data so you can see it's the EEG data and I'm taking the window onsets.

So for this iteration to the window onsets plus the length of the window.

So this just gets one small chunk out of the entire really long time series.

And let me set this here.

So I do.

Get one.

So now what I'm doing here.

So let me plot this data Chunk.

Plot data.

Chunk.

Like this.

So here's a little chunk of data.

And you also see in this one second snippet of data that there are a couple of rhythms.

So here's one.

This looks like a slow rhythm.

Maybe this corresponds to one hertz.

And what you see really prominently is these smaller, up and down cycles.

So we want to see whether this is really reliable, these rhythms and what their frequencies are.

Now, if I just take the Fourier transform of this signal exactly how it is, there's going to be some

edge artifacts, there's going to be some features introduced into the power spectrum that are not really

representative of what we want to look for in the signal.

And that's because the Fourier transform needs to capture this jump here up to zero.

And in particular this edge here from this data point down to zero.

So therefore what I want to do is taper this data snippet or apply a window.

And that's going to attenuate the signal in the beginning and attenuate the signal at the end, and

that will minimize the edge effects.

And that I do by applying something called a hann window.

So let me show you what this hann window looks like.

So plot on W so you can see it starts and ends at zero and it goes up to one.

So now when I apply this hann window to the data chunk.

You can see that the data are the same towards the middle and then they taper out to the end and they

taper out to the beginning.

And this is a way of minimizing the amount of edge effects that are contaminating the results of Welch's

method.

On the other hand, this is still valid data.

There's valid data here that we're attenuating and valid data here that we're attenuating.

And so this is one of the primary motivations of having overlapping windows.

That's why I specify this an overlap here.

So the idea is that this part of the signal is valid.

We don't want to completely throw it out.

We just want to attenuate it in this window.

Now imagine what happens in the next window, which starts halfway through this window.

Now, this is going to be towards the middle.

And a different part of the signal is going to be attenuated.

Okay, so once we apply the Han paper to the data, then I compute the power spectrum of the data chunk,

call it temp pow, and then I'm basically adding this temp pow variable to the EEG power.

And then this is for Welch's method.

And then after this loop where we go over all 238 windows in the data, I divide by the total number

of windows, and that gives me the average.

Okay.

And then it's just some plotting.

So let's see what this looks like.

The black line here corresponds to the static FFT.

So this was the Fourier transform from the entire data signal altogether, and the red line corresponds

to the Welch's method.

So you can see that the broad features of the signal is present in both the static FFT and in Welch's

method.

But the static FFT also has a lot more noise.

There's a lot more of these really small fluctuations compared to Welch's method, which looks a lot

smoother.

And the advantage here of Welch's method is that it allows us to focus more on the key parts of the

signal and be less distracted by these really small effects, which might just be noise.

In fact, you can imagine if you would smooth out the black line.

So if you take this power spectrum and apply some kind of smoothing or denoising strategy that you learned

about in the previous section of this course, then you would probably get something that looks really,

really similar to the red line.

Okay, Now, this is a lot of code up here.

And as I mentioned in the very, very beginning of this course, one of the first lectures in this course,

you don't necessarily have to write out all the code for yourself each time.

The point of me showing all this code and explaining all of this code is so that Welch's method doesn't

seem like it's some really bizarre, complicated, mysterious procedure.

It's actually pretty straightforward.

So in practice it's easier just to use the Matlab function.

P Welch.

Where is that?

That's here.

So the function P Welch and you input the data, you input a taper that you want to apply.

You input the number of points to overlap.

So I specified above that it should be 50% overlap and here it's going to be 25% overlap because I'm

dividing by four and then the end of the FFT.

I'll talk about this in a minute and the data sampling rate.

Okay.

So now I will run this cell and this is Matlab's version of the Welch's method.

So you can see it's not exactly like this red line here.

But it does look really similar.

In fact, you can look through the Matlab, P Welch code.

It's essentially doing what I have here, but it does a few extra things and it puts it in log scale

so it looks a little bit different.

But fundamentally the function P Welch is implementing something that looks an awful lot like this loop

here.

Okay?

So you can see that this plot looks nice and smooth.

It has a pretty high frequency resolution and that's because I specified the N of the F of T to be 10,000

points.

So this is a 10,000 point FFT even though it's only two seconds of data.

So the window is two seconds, but the FFT is 10s long, so there's a lot of zero padding, which means

that the frequency resolution gets higher, which basically just means that this plot gets smoother.

So you can try adjusting the frequency resolution by changing the n of the F of T.

So now I'm going to set this to be two seconds.

Actually, you know, I'll set this to be one second and this also to be one second.

And now you can see that this looks more similar to the red line here.

And I'll change this to be y axis in log scale.

So set get current axis y scale and let's make this logarithmic scale.

And now when you look at this red line, you can see it looks closer to this blue line.

All right, So let's see.

I'll set this back to two.

And this was ten before.

So now I can make this 100th.

This is kind of ludicrously long.

It's really a lot of smoothing.

But the important point is that the smoothing basically makes the plot look a little bit nicer.

But we still see the same fundamental features of the signal.

So that is a bump in the spectrum at ten hertz.

So there's strong rhythmicity in this signal at ten hertz or ten cycles per second.

And then there's also this kind of gentle decrease in power as a function of increasing frequency,

which is sometimes called one over F.

