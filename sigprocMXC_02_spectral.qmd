# Crash course on the fourier transform

The Fourier transform is a pretty wide topic. It is used in many  fields, such as mathematics, statistics, physics or engineering.

![FourierTransform](sigprocMXC_02_spectral/fourierTransformClear.png){#fig-transform-clear}

The idea of the Fourier transform is to transform the data from time domain to
frequency domain, and vice versa (inverse transform). @fig-transform-clear
panel A1 shows a signal in atime domain with a duration of two seconds.
Panel A2 shows the same signal in the frequency domain, with a single peak at
the three Hertz mark, as there are three cycles per second. The peak height is
one unit energy (amplitude), and 0 in any other point, as there are no other
frequencies. The signal in panel B1 has a peak at 8 Hertz (panel B2), with a
smaller amplitude (0.5 in both panels). Panel C1 shows the sum of these two
signals. However, in the time domain plot is not as easy to interpret as in the
other two examples, whereas the frequency domain clearly shows two distinct
spectral components with different frequencies and amplitudes. Frequency domain
visualization becomes even more useful if you start adding noise, whereas the
plot would be unreadable in the time domain
(@fig-transform-noisy contains 4 components with *broadband noise*).

![FourierTransform](sigprocMXC_02_spectral/fourierTransformNoisy.png){#fig-transform-noisy}

If a signal has certain features (sine-like repeating patterns)

The point is that there is the same information in both domains, but it is
easier to interpret in the frequency domain. Sine-like signals are particularly
amenable to this type of analysis, whereas other may be more difficult to
understand.

## How does the Fourier transform work?

How do you get from the time domain into the frequency domain using the
Fourier transform? On layman terms, you start off with a signal in the time
domain, and then you take a sine wave that you want to match against the signal.
The similarity between the signal and the wave is estimated with the
*dot product*. The result is a number indicating how much presence the wave
has within the signal. If we repeat this for waves with different frequencies,
we can make a frequency domain plot, where each of the bars is the similarity
of a wave obtained from the dot product (Fourier coefficients). The full plot
is called an amplitude or power spectrum, depending on wether the Fourier
coefficients have been squared or not. This procedure is called the forward
Fourier transform (from time domain to frequency domain).

Inverse Fourier transform, works in a similar way, allowing to transform data
in the frequency domain back to the time domain. It works by taking the Fourier coefficients, mapping them back onto pure sine waves and then summing them all
together. The usefulness of this technique has to do with some shortcuts that
people use in signal processing that are provided by the convolution theorem.

## Uses

There are two major uses of the Fourier Transform. One is making signals easier
to understand (spectral analysis), getting insights that would more difficult
to extract from the time domain. The other reason is because signal processing
operations in the frequency domain tend to be conceptually easier and faster
to implement on computers than the equivalent computations on the time domain.
For example filtering (convolution).

# Frequency resolution

Frequency resolution is the distance between any two successive frequency bins.
It is controlled by the sampling rates and of the number of time points in the
signal. The sampling rate leads to an important number in signal processing
and spectral analysis, which is called the Nyquist frequency.

The Nyquist frequency is very simply just half of the sampling rate. So if
you measure your data with a sampling rate of 1024Hz, then the Nyquist
frequency is 512Hz.

Now when you apply the forward Fourier transform on a signal the frequencies
you extract range from 0 (DC point), up to the Nyquist frequency, which is one
half of the sampling rate. The number of points you get between these two 
is a direct result of the number of time points in the signal.

* If you only have a few time points in the signal, then you're going to get a relatively
sparse frequency resolution.

* If you have more time points in the signal for the same sampling rate (a longer signal), then you're going to more data points between Zero and Nyquist (better frequency resolution).

If you want to increase the frequency resolution to get more frequencies out
of the signal, then you either need to have have more time points in the signal,
or you can do something called zero padding, which means adding more zeros to
the end of the signal, and that effectively makes the signal longer without
adding any new information into the signal.

# Fourier transform for spectral analyses

## Synthetic data

```{python}
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from scipy.io import loadmat, wavfile
from scipy import fftpack
from scipy import signal as spysig
from scipy.signal.windows import hann
import copy
```

In this video, we will go through some examples of the Fourier transform.
Some examples are based on simulated data, which can be very useful, as the
user can change the input signals (e.g., noise amount) with a known ground
truth.

We are going to simulate a signal with a sampling rate of 1234Hz with a length
of two seconds. In other words, 1234 time points per second per the definition
of the sampling rate in Hertz.

The time vector goes from 0 to the number of points minus one divided by the
sampling rate. Just linear indexing normalized by the sampling rate. Note this
vector does not go up to exactly, exactly two seconds. This is caused
by starting off at 0, if we started at one it would reach exactly two seconds.

```{python}
## Generate a multispectral noisy signal

# simulation parameters
srate = 1234 # in Hz
npnts = srate*2 # 2 seconds
time  = np.arange(0,npnts)/srate

# frequencies to include
frex  = [ 12,18,30 ]
```

If you go from zero up to the number of points, this is going to be two seconds
plus one sampling rate. Now, that's not really wrong per se, but it's
technically incorrect if you want to get two seconds of data.

So I'm going to generate a multi-spectral signal with three frequencies: 12Hz,
18Hz and 30Hz. First we initialize the signal to be just zeros plus noise.
Then we loop over the frequencies adding sine waves to the noise 
($\sin \left( 2 \pi f t \right)$). The indices are used as amplitudesS.

```{python}
signal = np.zeros(len(time))

# loop over frequencies to create signal
for fi in range(0,len(frex)):
    signal = signal + (fi+1)*np.sin(2*np.pi*frex[fi]*time)

# add some noise
signal = signal + np.random.randn(len(signal))
```

Once the signal has been generated, we extract the coefficients using the fast
Fourier transform (FFT). Then we use the absolute value (`abs`) to get the
magnitude from the coefficients, which is the amplitude.

If we intend to retrieve the original units of the signal, you do need to
normalize this data by multiplying by 2 and then divide by the number of time
points in the signal. However, if you are just interested in the shape of the
spectrum, you don't need either of these two.

The frequency vector is $1 + (n/2)$ (half of the time points) frequency bins
ranging between $0$ and Nyquist (half of the sampling rate).

```{python}
# amplitude spectrum via Fourier transform
signalX = fftpack.fft(signal)
signalAmp = 2*np.abs(signalX)/npnts

# vector of frequencies in Hz
hz = np.linspace(0,srate/2,int(np.floor(npnts/2)+1))

# Undo the transformation
remade = np.real(fftpack.ifft(signalX))
```

```{python}
## plots

plt.plot(time,signal, lw=1, label='Original')
plt.scatter(time, remade, s=4,c='k', lw=1, zorder=999,label='IFFT reconstructed')

plt.xlim(0.9, 1.1)
plt.xlabel('Time (s)')
plt.ylabel('Amplitude')
plt.title('Time domain')
plt.legend()
plt.show()

plt.stem(hz,signalAmp[0:len(hz)],'k')
plt.xlim([0,np.max(frex)*3])
plt.xlabel('Frequency (Hz)')
plt.ylabel('Amplitude')
plt.title('Frequency domain')
plt.show()
```

Then we plot the time domain signal and the amplitude spectrum of the signal.
You can clearly see that there are some rhythmicity components to this signal
and also a little bit of noise added here. The amplitude spectrum shows the
three peaks with the specified frequencies ($x$) and amplitudes ($y$) which
stand out from a background of uniformly distributed random noise (in the 
freq. domain; broadband noise?).

If we take the inverse Fourier transform (IFT) and we plot it in the time
domain we can see the original and the reconstructed signal overlap perfectly:
we can go into the frequency domain through the Fourier transform and then
apply the inverse Fourier transform and you get back the original signal
flawlessly.

Note if the signal is noisy enough, the components will not be clear on the
frequency domain.

If we increase the amplitude of the noise by multiplying by $3$ the signal 
remains understandable on the frequency domain. If we multiply by $6$, $16$,
$20$... the peaks stand less and less, with some becoming larger than the peaks
we introduced in the synthetic signal.

## Real world data: Search volume

```{python}
## example with real data based on 
# https://trends.google.com/trends/explore?date=today%205-y&geo=US&q=signal%20processing

data = {'original': np.load('sigprocMXC_02_spectral/GoogleTrends_SignalProcessing.npy')}
N = len(data['original'])
hz = np.linspace(0,52,N)

# possible normalizations...
data['centered'] = data['original'] - np.mean(data['original'])
data['detrended'] = spysig.detrend(data['original'])

# Plotting
fig, axes = plt.subplots(3, 2, sharex='col')
axes[0, 0].set_title('Time domain')
axes[0, 1].set_title('Frequency domain (power)')
for row_id, (ylabel, ydata) in enumerate(data.items()):

    axes[row_id, 0].set_ylabel(ylabel.capitalize())
    axes[row_id, 0].plot(ydata,'k')
    axes[row_id, 1].plot(hz, np.abs( fftpack.fft( ydata )/N )**2,'m')
    axes[row_id, 1].set_xlim(left=0, right=12)

axes[-1, 0].set_xlabel('Time (weeks)')
axes[-1, 1].set_xlabel('Frequency (norm)')
fig.tight_layout()
```

`GoogleTrends_SignalProcessing.npy` contains the search volume for
'signal processing' as depicted by [trends.google.com](https://trends.google.com).
These numbers are already normalized and have a weekly time step.

We get the amplitude spectrum by calcualating the FFT,
(dividing by the sample count?), and calculating the absolute value.
If it squared, it becomes the power spectrum.

On the left column of FIGURE you can see the weekly search volume seems to show
some rythmicity, and a slight downwards trend. The frequency domain plot for the
original signal seems to show nothing. That's not the case! It is heavily skewed
by the zero frequency: the DC offset (dark current offset?), which captures the
average over the full duration of the signal.

What is happening is the original signal has an average around 60, which becomes
3600 once it has been squared. Again, this first point only reflects the average
search volume, as it is not 0.

So it's often useful in signal processing to eliminate the DC component.
It can be removed during the plotting, or the data itself can be normalized,
for example, by removing the signal average, or by applying detrending.
Once any of these methods has been applied, the frequency domain plot becomes
a lot more readable now that the DC offset is 0.

Detrending may not be adequate on this case because it removes the downward
trend, which is a valid part of the signal. Removing the mean may be the right
procedure, retaining the slow decrease.

Interpretation. The data depicts the normalized search volume per week.
The ftequency vector (`hz`) goes from 0 to 52 with `N` steps (the length of the
data vector). This is different from the example with synthetic data where we
said $n/2 + 1$. Here we're applying a plotting trick to go all the way up to
$N$ because now I don't need to cut off the Fourier coefficients half way
through. This means that we can interpret these numbers as a fraction of a year.

The large peak at $2$ means that every $26$ weeks ($52/2$, twice a year), 
there is a peak in the search volume for signal processing. My guess is that
this corresponds to the semester schedule where twice a year people are starting
to learn about signal processing in their engineering course or perhaps a
statistics or data analysis course, and they start searching the internet for
signal processing information.

There's also a peak at one hertz, indicating the presence of an annual cycle.
There is also a large peak at low frequencies which could be interpreted as a
low frequency fluctuation in the signal. However, this is caused by the slow
linear trend, which requires a lot of energy at a kind of 1/f shape in the
frequency spectrum, and has spread over the two first coefficients, but it only
has been fully removed from the first (DC component removal).

# Welch's method

The Welch's Method is a slight variation of the fast Fourier transform (FFT).
Its purpose is to increase the signal-to-noise ratio (SNR), specially if the
signal changes over time (non-stationary).

So far we have applied the Fourier Transform ("static" FT) over a single window
covering the entire time series, which returns an amplitude/power spectrum.
The idea of Welch's method is to cut up the Time series into a set of
windows (also called blocks or epochs), and then apply a separate FT over each
of them, each returning its unique spectrum, averaging them afterwards.

If the features of the signal are the same over the entire window of time,
the static and the "moving" FT (Welch's) method are just the same. However,
if the signal or its noise change over time, then latter is going to give you
a slightly cleaner result (higher SNR).

The windows used in Welch's method may or may not ovrlap (e.g., 50% overlap
between consecutive windows).

We will illustrate this concept with some real data depicting electrical brain
activity (EEG) in a resting state (the person was sitting quietly with their
eyes closed and relaxing). The file contains the voltage fluctuations measured
by one electrode, and the other contains the sampling rate (1024 Hz).

We are going to create our own time vector with a vector ranging from 0 to
the measurement count minus one, and then divid by the sampling rate. Plot
PLOT depicts the data. It seems to contain 120 seconds of pure noise. However,
In 1-sec periods it becomes possible to see some regular fluctuations.

```{python}
# load data and extract
matdat  = loadmat('sigprocMXC_02_spectral/EEGrestingState.mat')
eegdata = matdat['eegdata'][0]
srate   = matdat['srate'].item()

# time vector
N = len(eegdata)
timevec = np.arange(0,N)/srate

# plot the data
plt.plot(timevec,eegdata,'k')
plt.xlabel('Time (seconds)')
plt.ylabel('Voltage ($\mu V$)')
plt.show()
print(srate)
```

In plot PLOT we compute the power over the entire EEG series

```{python}
# "static" FFT over entire period, for comparison with Welch
eegpow = np.abs(fftpack.fft(eegdata)/N )**2
hz = np.linspace(0,srate/2,int(np.floor(N/2)+1))
```

## "Manual" Welch's method

`winlength` defines how long the windows are going to be in terms of multiples
of the sampling rate. In this case, the window length will be one second, 1024
time points. `nOverlap` is the number of points shared by overlapping windows.
In this example, it is $1/2$ of the sampling rate (half of a second). Thus,
the windows have an overlap of 50% of the total window length. `winonsets`
contains the bounds of each Fourier transform [redact this better].

Note the frequency resolution of the Fourier transform is given by the number
of time points. In the case of the static FT we have a lot of time points, but
with Welch's method we only have those that are within the window.

We need a different frequencies vector for the static power spectrum Vs. the
smaller Fourier transform that's going to result from Welch's method. This
vector `eegpowW` is initialized to 0's because we are going to keep adding
power onto itself to compute the average over all of these window onsets.

Then, we loop over the window onsets, take a chunk of the EEG data starting on
the onset and ending on the onset plus the length of the window.

If we just take the Fourier transform of the windows, there are going to be some
edge artifacts: features introduced into the power spectrum that are not really
representative of what we want to look for in the signal.

And that's because the Fourier transform needs to capture the jump from 0 to
the start of the signal, and going back to 0 after the end of the signal. 

Thus, I want to taper this data snippet (apply a window). That is going to
attenuate the the beginning and the end of the signal, minimize the edge effects.

In this case, we apply the Hann window (plot PLOT). It starts at 0, goes up to
one, and goes back to 0. When I apply this window to the data chunk we see is
the same towards the middle, but the beginning and the end taper out. This is a
way of minimizing the amount of edge effects that are contaminating the results
of Welch's method.

Note we are attenuating valid data at he start/end of the windows, and thats
the main reason behind the overlapping windows: what is the edge in a specific
window will be the at the center in the next.

Once we apply the Han paper to the data, then I compute the power spectrum of
the data chunk (`temppow`), and adding it to the variable to the EEG power
(`eegpowW`). After looping over all 238 windows in the data, I divide by the
total number of windows to calculate the the average.

In figure FIGURE the black line corresponds to the static FFT computed based on 
the entire signal, and the the red line corresponds to the Welch's method. Both
plots seem to share the same broad features, but the spectrum for the static
FFT is noisier the one obtained with Welch's method, which looks a lot smoother.
Welch's method allows to focus on the key parts of the signal disregarding 
small effects, which might be noise.



```{python}
# window length in seconds*srate
winlength = int( 1*srate )

# number of points of overlap
nOverlap = np.round(srate/2)

# window onset times
winonsets = np.arange(0,int(N-winlength),int(winlength-nOverlap))

# note: different-length signal needs a different-length Hz vector
hzW = np.linspace(0,srate/2,int(np.floor(winlength/2)+1))

# Hann window
hannw = .5 - np.cos(2*np.pi*np.linspace(0,1,int(winlength)))/2

# initialize the power matrix (windows x frequencies)
eegpowW = np.zeros(len(hzW))

# loop over frequencies
for wi in range(0,len(winonsets)):
    
    # get a chunk of data from this time window
    datachunk = eegdata[ winonsets[wi]:winonsets[wi]+winlength ]
    
    # apply Hann taper to data
    datachunk = datachunk * hannw
    
    # compute its power
    tmppow = np.abs(fftpack.fft(datachunk)/winlength)**2
    
    # enter into matrix
    eegpowW = eegpowW  + tmppow[0:len(hzW)]

# divide by N
eegpowW = eegpowW / len(winonsets)


# plotting
plt.plot(hz,eegpow[0:len(hz)],'k',label='Static FFT')
plt.plot(hzW,eegpowW/10,'r',label='Welch''s method')
plt.xlim([0,40])
plt.xlabel('Frequency (Hz)')
plt.legend()
plt.show()
```

## Scipy's Welch's method

So far we have written our own code to showcase the inner workings of Welch's
method. Scipy has its own implementation , which ingests the frequency (`fs`),
the taper finction or `window`, the samples per window (`nperseg`), the number
of shared samples between segments (`noverlap`), and the number of FFT points
(`nfft`, the frequency resolution). The example of figure FIGURE has a 25%
overlap

```{python}
## Python's welch

# create Hann window
winsize = int( 2*srate ) # 2-second window
hannw = .5 - np.cos(2*np.pi*np.linspace(0,1,winsize))/2

# number of FFT points (frequency resolution)
nfft = srate*100

print(srate, nfft)

f, welchpow = spysig.welch(eegdata,fs=srate,window=hannw,nperseg=winsize,noverlap=winsize/4,nfft=nfft)

plt.plot(f,welchpow) # plt.semilogy() to plot in log scale
plt.xlim([0,40])
plt.xlabel('frequency [Hz]')
plt.ylabel('Power')
plt.show()
```

The figure FIGURE looks very smooth because it has a high frequency
resolution due the high count of FFT bins we specified (`nfft = 10 * srate`).
The window has has a length of 2 seconds, but the FFT is 10s long, meaning
there's a lot of zero padding, increasing the frequency resolution. If we set
`nfft` to be just 1 second the line becomes more similar to the PREVIOUS FIGURE.
Larger values of `nfft` increase the smoothing. Regardless of the window size,
we still see the same fundamental features of the signal with a bump at ten
hertz.

# Spectrogram of birdsong

Welch's method works by computing the FT of lots of successive windows of time,
and then you average all the power spectra together. If we apply Welch's method
over a signal whose properties change over time, the changed information would
be lost during the averaging.

Time Frequency analysis offers an alternative (related to wavelet analysis).
[...] A spectrogram is...

We are going to calculate the spectrogram of a birdsong. If we play the audio
file we can hear a bird call accompanied by other bird sounds. Loading the file
with `scipy.io.wavfile`, returns the frequency (`sf`) and a 2D array (`bc`),
where the rows are the time steps are the 2 channels. In this case the time
vector needs to be created from the frequency. Figure FIGURE depict both
channels in the time domain.

```{python}
## load in birdcall (source: https://www.xeno-canto.org/403881)

fs,bc = wavfile.read('sigprocMXC_02_spectral/XC403881.wav')


# create a time vector based on the data sampling rate
n = len(bc)
timevec = np.arange(0,n)/fs

# plot the data from the two channels
fig, axes = plt.subplots(nrows=2, sharex=True)
axes[0].set_title('Time domain')
for channel in [0, 1]:
    axes[channel].set_ylabel(f"Channel {channel + 1}")
    axes[channel].plot(timevec, bc[:, channel], lw=.1)
axes[1].set_xlabel('Time (sec.)')
fig.tight_layout()
```

Figure FIGURE shows the power spectrum for channel 2.
It shows a little bit of a low frequency offset and frequencies, and some stuff
at higher frequencies. However, most of the energy of the signal is in the
range beweeen 2.0 and 2.5 KiloHertz, the range of the bird call for this
particular recording.

The plot illustrates the limitation of applying a static Fourier transform
covering the entire signal: apart from the bird call there is other stuff,
like other birds. However, the three spikes of the power spectrum correspond
to the bird that was singing, but they do not really reflect all the details
contained in the audio.

```{python}
# compute the power spectrum
hz = np.linspace(0,fs/2,int(np.floor(n/2)+1))
bcpow = np.abs(fftpack.fft( spysig.detrend(bc[:,0]) )/n)**2

# now plot it
plt.plot(hz,bcpow[0:len(hz)])
plt.xlabel('Frequency (Hz)')
plt.title('Frequency domain')
plt.xlim([0,8000])
plt.show()
```



So far we have plotted the signal in both the time and the frequency domains,
each provide unique information. If we want to display frequency ($y$) changes
over time ($x$) we can use the `spectrogram`, where the color depicts the 
amplitude or the power of the signal (squared magnitude).

```{python}
## time-frequency analysis via spectrogram

frex,time,pwr = spysig.spectrogram(bc[:,0],fs)

plt.pcolormesh(time,frex,pwr,vmin=0,vmax=100)
plt.xlabel('Time (s)'), plt.ylabel('Frequency (Hz)')
plt.show()
```

Most of the energy is in the range 2.0 - 2.5, with some energy between 5 and
6 kHz (horizontal bar spanning most of the recording), which would be the high
frequency components we saw on the frequency domain plot (FIGURE).
There is also some **broadband** bursts (vertical lines).

This example shows a real world example of how different sources can be
embedded in different frequency ranges in the same recording.

By using these tools we will be able to separate bird calls from one another
using narrowband filtering.

# Manual creation of a spectrogram

With Welch's method, you would compute the power spectrum separately for each
of these windows, and then you would average those results. Here, we are
creating a time frequency plot (spectrogram), placing the power spectrum of
each window into a matrix (500 ms windows, no overlap).

We are going to create a spectrogram using the contents of a `.mat` file,
shich contains the sampling rate, the time vector, and a signal called 'chirp'.
It is a type of sine wave starting with a smaller frequency (~10 Hz) that
increases up to a point (~25 Hz), and then decreases, remaining at a frequency
larger than the starting one (~20 Hz).

```{python}
# Load and simplify
chirp_mat = loadmat('sigprocMXC_02_spectral/spectral_codeChallenge.mat')
chirp_time, chirp_signal = chirp_mat['time'][0], chirp_mat['signal'][0]
chirp_freq = chirp_mat['srate'].item()

# Make the time bins
win_len = int(.5 * chirp_freq)
win_edges = np.arange(0, len(chirp_signal) + 1, win_len)
win_times = chirp_time[win_edges]
win_count = len(win_edges) - 1

# Make the frequency bins
freq_edges = np.linspace(0, chirp_freq, win_len + 1) # FFT return is symmetric

# Prepare the spectrogram
man_spec = np.zeros((win_len, win_count))
taper = hann(win_len)
for win_idx, win_end in enumerate(win_edges[1:]):
    win_start = win_end - win_len
    chunk = chirp_signal[win_start:win_end]
    man_spec[:, win_idx] = np.abs(fftpack.fft(taper * chunk)/win_count)**2

# plot
fig, axes = plt.subplots(nrows=2, sharex=True)
axes[0].set_title('Time-domain signal')
axes[0].plot(chirp_time, chirp_signal, alpha=.75)
axes[1].set_title('Spectrogram')
axes[1].set_ylabel('Frequency (Hz)')
axes[1].pcolormesh(win_times, freq_edges, man_spec, cmap='Greys')
axes[1].set_ylim(top=40)
axes[1].set_xlabel('Time (s)');
fig.tight_layout()
```
